### Leave one out cross validation

The `VSURF` package selected some features using random forest https://github.com/crazyhottommy/Epigenome_RoadTrip/blob/master/daily_notes/2018-03-15_day3.md#think-about-using-heatmap-to-visualize-all-features.

I am going to test how good the model is with only the features being selected.

```{r}
library(VSURF)

set.seed(1973)
cols2use = sample(1:ncol(x_data), 2500)
test_data<- x_data[,cols2use]

ti<- proc.time()

# sqrt(p) is the default of mtry
## takes one hour using 4 cpus with 2500 features
vsurf <- VSURF(x = test_data, y = resp_data$X2, ntree = 500, parallel =T, ncores = 4, mtry = 50)
proc.time() - ti

names(vsurf)
summary(vsurf)

plot(vsurf)
vsurf$varselect.thres
vsurf$varselect.interp
vsurf$varselect.pred
```

### use caret for cross-validation

```{r}
library(caret)

# caret package https://machinelearningmastery.com/feature-selection-with-the-caret-r-package/
## create dummy variables, caret assumes the predictors to be numeric. takes forever...

## now subset the X matrix with only the variables
features_sel<- vsurf$varselect.interp

cv_data<- cbind(test_data[,features_sel], tissue = factor(resp_data$X2))
dummies <- dummyVars(tissue ~ .,  data = cv_data)
head(predict(dummies, newdata = cv_data))

new_x<- predict(dummies, newdata = cv_data)
## ?rfeControl or the ?trainControl
control <- rfeControl(functions=rfFuncs, method="LOOCV")

fitControl<- trainControl(method = "LOOCV", classProbs = TRUE)

set.seed(825)

## not working
rfFit <- train(x = new_x, y=cv_data$tissue,
                 method = "rf",
                 trControl = fitControl,
                 verbose = TRUE)

```

### just use randomForest package

`caret` is not happy with categorical predictors...

```{r}
library(randomForest)
cv_data
rf_mod<- randomForest(tissue ~ ., data = cv_data[-1,])
rf_mod
predict(rf_mod, new_data = cv_data[1,-ncol(cv_data)], type = "response")
getTree(rf_mod)


### leave one out cross-validation

predicts<- list()
for (i in 1:nrow(cv_data)){
        data<- cv_data[-i, ]
        # the last column is the response
        new_data<- cv_data[i, -ncol(cv_data)]
        rf_mod<- randomForest(tissue ~ ., data = data )
        rf_predict<- predict(rf_mod, newdata = new_data, type = "response")
        predicts<- c(predicts, list(data.frame(predict = rf_predict)))
}


cbind(purrr::reduce(predicts, rbind), cv_data$tissue)
```

No error was made! impressive!


### Time to prepare our own tumor data

```bash
cd /rsrch2/genomic_med/krai/scratch/TCGA_CCLE_SKCM/SKCM_MSTC_CCLE_RUN/snakemake_ChIPseq_pipeline/12chromHMM
mkdir 20SKCM_chromHMM

cp 16CCLE_10MSTC_20_SKCM_CHROMHMM_OUTPUT/M*-P*segments.bed 20SKCM_chromHMM/
cd !$

ls
M028-P008_18_segments.bed  M263-P011_18_segments.bed  M357-P010_18_segments.bed  M642-P008_18_segments.bed  M807-P010_18_segments.bed
M035-P010_18_segments.bed  M275-P008_18_segments.bed  M399-P010_18_segments.bed  M721-P010_18_segments.bed  M822-P010_18_segments.bed
M137-P008_18_segments.bed  M305-P009_18_segments.bed  M409-P011_18_segments.bed  M749-P010_18_segments.bed  M852-P008_18_segments.bed
M233-P010_18_segments.bed  M306-P008_18_segments.bed  M527-P010_18_segments.bed  M762-P008_18_segments.bed  M857-P010_18_segments.bed

# clean the file names a bit

brename -p "-P[0-9]{3}" -r "" ^C

ls
M028_18_segments.bed  M263_18_segments.bed  M357_18_segments.bed  M642_18_segments.bed  M807_18_segments.bed
M035_18_segments.bed  M275_18_segments.bed  M399_18_segments.bed  M721_18_segments.bed  M822_18_segments.bed
M137_18_segments.bed  M305_18_segments.bed  M409_18_segments.bed  M749_18_segments.bed  M852_18_segments.bed
M233_18_segments.bed  M306_18_segments.bed  M527_18_segments.bed  M762_18_segments.bed  M857_18_segments.bed

```

#### tile the segments to 1kb bin.

```r
library(GenomicRanges)
library(rtracklayer)
library(purrr)
library(tidyverse)
options(scipen=500)

segs<- list.files(".", pattern = "segments.bed")

segs<- set_names(segs, gsub("_18_segments.bed", "", segs))
chromHMM_segs<- purrr::map(segs, import, format = "BED")

tile_chromHMM<- function(chromHMM_seg){
  chromHMM_seg_tile<- tile(chromHMM_seg, width = 1000)
  names(chromHMM_seg_tile)<- chromHMM_seg$name
  stack(chromHMM_seg_tile, "state")
}

# this can take a while..
chromHMM_tiles<- map(chromHMM_segs, tile_chromHMM)

## write back to file as a bed file. bed file is 0 based, in R, everything is 1 based.
## start(gr) -1

make_df<- function(gr){
  data.frame(chr = seqnames(gr), start = start(gr) - 1, end = end(gr), state = gr$state)
}

chromHMM_dfs<- map(chromHMM_tiles, make_df)

walk2(chromHMM_dfs, names(chromHMM_dfs), function(x,y) write.table(x, paste0(y, "_segments.bed"), row.names =F, col.names =F, sep = "\t", quote =F))

```

#### make a dataframe

```bash
rm *18_segments.bed
s -sh
total 1.6G
81M M028_segments.bed  82M M263_segments.bed  82M M357_segments.bed  82M M642_segments.bed  82M M807_segments.bed
82M M035_segments.bed  82M M275_segments.bed  82M M399_segments.bed  82M M721_segments.bed  82M M822_segments.bed
82M M137_segments.bed  82M M305_segments.bed  82M M409_segments.bed  82M M749_segments.bed  82M M852_segments.bed
82M M233_segments.bed  82M M306_segments.bed  82M M527_segments.bed  82M M762_segments.bed  82M M857_segments.bed
```

In our in-house data set, we run chromHMM with a bin size of 1000 bp, that greatly reduced the file size. I will not
split by chromosome as I did for our testing steps for the epigenome Roadmap data (200bp bin size).

```{r}
library(tidyverse)
library(purrr)
library(stringr)
options(scipen=500)

## important to write, R will change 400000 to 4e+05, this may cause troubles

files<- list.files(".", pattern = "segments.bed")

file_list<- map(files, read_tsv, col_names =F)

seg_df<- purrr::reduce(file_list, left_join, by = c("X1", "X2", "X3"))

sample_names<- str_replace(files,  "_segments.bed", "")
colnames(seg_df)<- c("chr", "start", "end",  sample_names)

write.table(seg_df, "SKCM_seg_df.tsv", sep = "\t", col.names =T, row.names = F, quote =F)
```

#### merge bins

use `merge_bin.py`:

```bash

./merge_bin.py --ifile SKCM_seg_df.tsv --ofile SKCM_seg_merged_df.tsv

```

#### filtering

```{r}
seg_df<- read.table("SKCM_seg_merged_df.tsv", header =T, stringsAsFactor = F)
seg_df_state<- dplyr::select(seg_df, -chr, -start, -end)

seg_df_state<- as.data.frame(seg_df_state)

## test if every column has the same string for every row

apply(seg_df_state, 1, function(x) length(unique(x)) == 1) %>% table()

ind<- apply(seg_df_state, 1, function(x) length(unique(x)) == 1)

seg_df_sub<- seg_df[!ind, ]

write.table(seg_df_sub, "SKMC_seg_df_sub.tsv", sep = "\t", col.names =T, row.names = F, quote =F)
```

#### further filtering

```{r}
library(dplyr)
library(rlang)
library(caret)

meta_data<- read.table("data/epigenome_SKCM/tumor_meta.txt", stringsAsFactors = F, sep = "\t", header =T)

## need to figure out a better way to select the columns...
new_data<- seg_df_sub %>% distinct(M028, M035, M137, M233, M263, M275, M305, M306, M357, M399, M409, M527, M642, M721, M749, M762, M807, M822, M852, M857, .keep_all = T)

dim(seg_df_sub)
[1] 1556687      23

dim(new_data)
[1] 1371923      23

x_data<- as.matrix(new_data[,-c(1:3)])

rownames(x_data)<- paste(new_data$chr, new_data$start, new_data$end, sep = ":")

## transpose the matrix.
x_data<- t(x_data)

## random forest does not like matrix if it is not numeric. turn back to a dataframe
x_data<- data.frame(x_data)

resp_data<- merge(x = data.frame(sample = rownames(x_data)), y = meta_data, by.x = "sample", by.y = "sample", all.x = T, all.y = F)

save(x_data, resp_data, file = "SKCM_rf_input.rda")
```
