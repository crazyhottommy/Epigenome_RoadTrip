### reprepare our own tumor data set using my pipeline

I have prepared our own tumor data set on [day4](https://github.com/crazyhottommy/Epigenome_RoadTrip/blob/master/daily_notes/2018-03-16_day4.md#time-to-prepare-our-own-tumor-data)

Since I wrote a [snakemake pipeline](https://github.com/crazyhottommy/pyflow-epilogos), I will re-process it with the pipeline.
Moreover, the tumor data were called by chromHMM using 18states. some states can
be combined.

![](https://github.com/crazyhottommy/Epigenome_RoadTrip/blob/master/pics/emissions_18.png)

E1 and E2 are both active enhancers. E3 and E16 are low states. E4 and E5 are both transcribed enhancers.
E12 is artifacts, enriched for every histone mark.

The 18 state model can be combined to 15 state.


I will use scripts to do the [state recoding](https://github.com/crazyhottommy/pyflow-epilogos/blob/master/scripts/recode_dense_seg_state_color.py) and [bin merging](https://github.com/crazyhottommy/pyflow-epilogos/blob/master/scripts/merge_bin.py).

Finally, I will import to R and do filtering of the features.

```bash
ssh railab
cd /rsrch2/genomic_med/krai/scratch/TCGA_CCLE_SKCM/SKCM_MSTC_CCLE_RUN/snakemake_ChIPseq_pipeline/12chromHMM
rm 20SKCM_chromHMM/*
cp 16CCLE_10MSTC_20_SKCM_CHROMHMM_OUTPUT/M*-P*segments.bed 20SKCM_chromHMM/

ls 20SKCM_chromHMM/
M028-P008_18_segments.bed  M275-P008_18_segments.bed  M409-P011_18_segments.bed  M762-P008_18_segments.bed
M035-P010_18_segments.bed  M305-P009_18_segments.bed  M527-P010_18_segments.bed  M807-P010_18_segments.bed
M137-P008_18_segments.bed  M306-P008_18_segments.bed  M642-P008_18_segments.bed  M822-P010_18_segments.bed
M233-P010_18_segments.bed  M357-P010_18_segments.bed  M721-P010_18_segments.bed  M852-P008_18_segments.bed
M263-P011_18_segments.bed  M399-P010_18_segments.bed  M749-P010_18_segments.bed  M857-P010_18_segments.bed

cd ~/scratch
mkdir SKCM_RoadTrip
cd SKCM_RoadTrip
git clone https://github.com/crazyhottommy/pyflow-epilogos
source activate py351
module load R/3.4.1-shlib
cd pyflow-epilogos/

# I modified the sample2json.py a bit to only extract M028 rather than M028-P008 as the sample name.
 python3 sample2json.py --segment_dir /rsrch2/genomic_med/krai/scratch/TCGA_CCLE_SKCM/SKCM_MSTC_CCLE_RUN/snakemake_ChIPseq_pipeline/12chromHMM/20SKCM_chromHMM/

 cat  ~/scratch/TCGA_CCLE_SKCM/SKCM_MSTC_CCLE_RUN/snakemake_ChIPseq_pipeline/12chromHMM/16CCLE_10MSTC_20_SKCM_CHROMHMM_OUTPUT/M028-P008_18_dense.bed | sed '1d' | cut -f4,9 | sort -k1,1V |  uniq | tee my_map.txt
1       0,0,255
2       51,102,255
3       0,153,204
4       0,255,255
5       51,255,153
6       51,255,0
7       0,204,51
8       0,102,0
9       0,0,51
10      204,0,51
11      255,0,204
12      204,153,255
13      204,204,102
14      255,255,0
15      255,255,204
16      102,51,153
17      51,102,102
18      102,153,51

## edit the my_map.txt by hand, add header.

cat my_map.txt
old_state       new_state       new_color
1       1       0,0,255
2       1       0,0,255
3       2       0,153,204
4       3       0,255,255
5       3       0,255,255
6       4       51,255,0
7       5       0,204,51
8       6       0,102,0
9       7       0,0,51
10      8       204,0,51
11      9       255,0,204
12      10      204,153,255
13      11      204,204,102
14      12      255,255,0
15      13      255,255,204
16      2       0,153,204
17      14      51,102,102
18      15      102,153,51

nano config.ymal
# epilogos, WT: 2,18,20  NRAS: 1,10,13,19  BRAF: 3-9,11-12,14-17

./pyflow-epilogos.sh

```
Finishes within minutes.

### merging

```bash
cd 03combine_sample_segs
ls
combined_seg.txt  epilogos_input.txt

# the combined_seg.txt has a header.
wc -l
3095682 combined_seg.txt
3095681 epilogos_input.txt
6191363 total

## 3 billion base across genome, 1kb get down to 3 million bins! about right:)

# merge the bins
../scripts/merge_bin.py --ifile combined_seg.txt --ofile SKCM_merged_seg.tsv

wc -l *
3095682 combined_seg.txt
3095681 epilogos_input.txt
1537399 SKCM_merged_seg.tsv

# this cut down the features to 1.5 million.
```

### filtering

```r
library(tidyverse)
library(readr)
seg_df<- read.table("SKCM_merged_seg.tsv", header =T, stringsAsFactor = F)
seg_df_state<- dplyr::select(seg_df, -chr, -start, -end)

seg_df_state<- as.data.frame(seg_df_state)

## test if every column has the same string for every row

apply(seg_df_state, 1, function(x) length(unique(x)) == 1) %>% table()

ind<- apply(seg_df_state, 1, function(x) length(unique(x)) == 1)

seg_df_sub<- seg_df[!ind, ]

write.table(seg_df_sub, "SKCM_seg_df_sub.tsv", sep = "\t", col.names =T, row.names = F, quote =F)

```

### further filtering

```r
library(dplyr)
library(rlang)
library(caret)

meta_data<- read.table("data/epigenome_SKCM/tumor_meta.txt", stringsAsFactors = F, sep = "\t", header =T)

## need to figure out a better way to select the columns...
new_data<- seg_df_sub %>% distinct(M028, M035, M137, M233, M263, M275, M305, M306, M357, M399, M409, M527, M642, M721, M749, M762, M807, M822, M852, M857, .keep_all = T)

dim(new_data)
[1] 1218880      23
> dim(seg_df_sub)
[1] 1518714      23

## cut down to 1.2 million features across the genome.

x_data<- as.matrix(new_data[,-c(1:3)])

rownames(x_data)<- paste(new_data$chr, new_data$start, new_data$end, sep = ":")

## transpose the matrix.
x_data<- t(x_data)

## random forest does not like matrix if it is not numeric. turn back to a dataframe
x_data<- data.frame(x_data)

resp_data<- merge(x = data.frame(sample = rownames(x_data)), y = meta_data, by.x = "sample", by.y = "sample", all.x = T, all.y = F)

save(x_data, resp_data, file = "SKCM_rf_input.rda")
```
