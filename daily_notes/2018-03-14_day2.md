### merge the bins

chromHMM combines the consecutive bins if they are of the same state for one sample. Similarly,
we can combine the consecutive bins together if they are of the same states across samples. In this
way, the number of segments (features) can be reduced.

e.g.

```
chr1    0   200 E1  E2  E2  E3
chr1    200 400 E1  E2  E2  E3
chr1    400 600 E2  E2  E2  E3

will be merged to

chr1    0   400 E1  E2  E2  E3
chr1    400 600 E2  E2  E2  E3

```

I wrote a python script for merging the bins in the `scripts` folder: [`merge_bin.py`](https://github.com/crazyhottommy/Epigenome_RoadTrip/blob/master/scripts/merge_bin.py).

```bash
cd /rsrch2/genomic_med/krai/epigenome_roadmap/concept_learning_chromHMM_segs/chr1_segments
time ./merge_bin.py --ifile seg_df_chr1.tsv --ofile seg_df_chr1_merged.txt
real    0m3.975s
user    0m3.846s
sys     0m0.094s

wc -l seg_df*
423390 seg_df_chr1_merged.txt
993553 seg_df_chr1_sub.tsv
1246254 seg_df_chr1.tsv
```
The number of segments dropped from 1246254 to 423390. `seg_df_chr1_sub.tsv` is the file generated from [day1](https://github.com/crazyhottommy/Epigenome_RoadTrip/blob/master/daily_notes/2018-03-13_day1.md) after filtering but
without merging consecutive bins.
Lisa and I figured out to merge the bins first and then do the filtering. `seg_df_chr1_sub.tsv` can be removed for now.

I will need to use `seg_df_chr1_merged.txt` to the same filtering.

**filter out segments with the same states across samples**

```r
seg_df<- read.table("seg_df_chr1_merged.txt", header =T, stringsAsFactor = F)
seg_df_state<- dplyr::select(seg_df, -chr, -start, -end)

seg_df_state<- as.data.frame(seg_df_state)

## test if every column has the same string for every row

apply(seg_df_state, 1, function(x) length(unique(x)) == 1) %>% table()
.
FALSE   TRUE
417480   5909

ind<- apply(seg_df_state, 1, function(x) length(unique(x)) == 1)

seg_df_sub<- seg_df[!ind, ]

write.table(seg_df_sub, "seg_df_chr1_sub.tsv", sep = "\t", col.names =T, row.names = F, quote =F)
```

Now, the `seg_df_chr1_sub.tsv` file contains 417481 regions after filtering.


```bash
wc -l seg_df*
   423390 seg_df_chr1_merged.txt
   417481 seg_df_chr1_sub.tsv
  1246254 seg_df_chr1.tsv

```

### re-download the data

Lisa has suggested to use `Heart`, `Digestive` and `Epithelial` tissues.

I will replace `neurosph`  with `Heart` samples.

Repeat everything.

```bash
cd  /rsrch2/genomic_med/krai/epigenome_roadmap/concept_learning_chromHMM_segs/chr1_segments

wc -l seg*
448286 seg_df_chr1_merged.txt  # merged file  for 25 samples
443324 seg_df_chr1_sub.tsv  # merged and then filered
1246254 seg_df_chr1.tsv  # chromHMM 200bin tiled orignal file

```


### different bin with the same states combination across samples

see https://github.com/crazyhottommy/getting-started-with-genomics-tools-and-resources/blob/master/R_tricks.md#add-a-unique-id-for-rows-with-the-same-values-on-columns

add a id for each distinct combination of states acorss samples regardless of the bin locations.

```r
seg_df_sub_pattern<- seg_df_sub %>% mutate(pattern = group_indices_(seg_df_sub, .dots = names(seg_df_sub)[-c(1:3)]))

# how frequent?
seg_df_sub_pattern %>% group_by(pattern) %>% summarise(number = n()) %>% arrange(desc(number))

```
